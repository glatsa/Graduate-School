{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Desktop'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir('/Users/gml/Desktop')\n",
    "#path1 ='/Users/gml/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from CSV into a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'i\\'m really starting to wonder about alicia silverstone . \\nsure , she is one of the most beautiful creatures on god\\'s green earth ( second only to that movie critic at large guy ) , but when it comes to choosing what movies she stars in , she always strikes out . \\nthe crush was a slow-moving , predictable piece of fluff . \\nhideaway was a horrific novel adaptation alicia had only a minor role in . \\nclueless was an annoying , unfunny waste of time . \\nand people have e-mailed me too ,\" saying clueless is a good movie and that i\\'m the only one who doesn\\'t like it . \\none girl said if i\\'d seen the movie with \\\"\" an open mind \",\" \\\"\" i would have enjoyed it . \\nnothing could be further from the truth . \\ni went into the theater expecting to love the movie . \\nthe preview looked good and of course i\\'m crazymadinlove with alicia \", but the movie was a bunch of bad jokes coming from whiny , unlikable characters . \\nalmost everyone i saw the movie with felt the same way . \\nwhen we were walking out of the theater , one guy ( and it wasn\\'t me ) yelled out ,\" \\\"\" that was the worst f$&#in\\' movie i\\'ve ever seen \\\"\" and the rest of us had to laugh in agreement . \\nso last night i walked into the video store and saw alicia\\'s pretty face on the cover of some made-for-video thriller called the babysitter . \\ni knew it would be bad but some inner compulsion i\\'ll probably never understand made me rent it anyway . \\nwhat i got was 90 minutes of regret--the worst alicia silverstone movie ever . \\nand you already know from the last paragraph what the competition is like . \\nwhere to begin in criticizing this movie ? \\nthe plot is a thin shred that moves slower than a glacier \", the writing could have been done ( and for all we know it was ) by a ten year old , alicia is the star and she\\'s still wasted in a movie that has no appeal whatsoever . \\nthere is zero humor , zero suspense , zero drama and zero action , until the last ten minutes , when the story is needlessly and pointlessly concluded with a violent sequence . \\nzero plus zero plus zero plus zero equals zero . \\nso why does this movie get one star out of me ? \\nwell , alicia spends twenty minutes of the movie in the bathtub . \\nand if it wasn\\'t bubble bath , the babysitter would have instantly joined the ranks of our other four- star features , but you settle for what you can get . \\nalicia plays a babysitter who\\'s spending friday night looking after two kids whose parents are out getting drunk at a cocktail party . \\nand of course anyone as beautiful as alicia automatically spends their friday nights at home ( at least that movie critic at large guy does ) . \\nas the movie trods along , we discover she\\'s not only the mostly-silent star of the movie but also the object of every male character\\'s fantasies ( and probably every male viewer\\'s too ) . \\nthe drunken father thinks she\\'s just the thing to recapture his lost youth , her boyfriend lets his imagination run wild while spying on alicia from outside , even the prepubescent boy looks in on alicia through the bathroom keyhole while she\\'s taking her bubble bath . \\nthey even throw in the middle aged wife\\'s fantasies about a male counterpart at the party . \\nnot that any of us asked or ever even thought about seeing this 200+ pound woman in a black silk teddy . \\nat least none of the sex fanatasies ever leave the realm of the pg-rated . \\nin fact , i could imagine the babysitter becoming a cinemax late-night staple if not for the fact that there\\'s absolutely no nudity in it . \\nso you can\\'t call it a sex flick . \\ni\\'ve already pointed out that it can\\'t fall under drama , comedy , thriller or action , so what do you classify the babysitter as ? \\nbad . \\n',neg,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('MovieDataSAMPLE_labeledVERYSMALL.csv', delimiter='\\n', header = None)\n",
    "data = data.drop(0, axis = 0)\n",
    "data = data.rename(columns={0: 'Comments'})\n",
    "data[\"Label\"] = np.nan\n",
    "#print(data.head())\n",
    "print(data.iloc[2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Comments     Label\n",
      "1  'let\\'s say you live at the end of an airport ...  Positive\n",
      "2  'in this good natured , pleasent and easy goin...  Positive\n",
      "3  'i\\'m really starting to wonder about alicia s...  Negative\n",
      "4  'so what do you get when you mix together plot...  Negative\n",
      "5  'the law of crowd pleasing romantic movies sta...  Negative\n"
     ]
    }
   ],
   "source": [
    "for row in data.index:\n",
    "    a = data.iloc[row-1,0]\n",
    "    if a[-1] == 's':\n",
    "        data.iloc[row-1,0] = a[0:len(a)-4]\n",
    "        data.iloc[row-1,1] = 'Positive'\n",
    "    else:\n",
    "        data.iloc[row-1,0] = a[0:len(a)-4]\n",
    "        data.iloc[row-1,1] = 'Negative'\n",
    "\n",
    "RowNames = \"Review #\" + data.index.map(str) + ': ' + data[\"Label\"]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning for the Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   ', '\\n1 ', ' . ', ' , ', ' ? ', ' ( ', ' ) ', ' a ', ' i ', ' : ', ' - ', '\\n2 ', '1', '9', '8', '4', '\\n3 ', '0', '2', '\\n4 ', '3', ' ! ', '\\n5 ', ' v ']\n"
     ]
    }
   ],
   "source": [
    "## Uses regual Expressions to find extra texts to remove for later\n",
    "\n",
    "mylist = data.to_string()\n",
    "ntl = re.findall(r\"\\s.\\s|[0-9]\",mylist)\n",
    "new_ntl = list(dict.fromkeys(ntl))\n",
    "issues1 = []\n",
    "fixes1 = []\n",
    "\n",
    "print(new_ntl)\n",
    "for row in new_ntl:\n",
    "    if not any(a.isalnum() for a in row):\n",
    "        if row == ' ( ':\n",
    "            issues1.append(' ( ')\n",
    "            fixes1.append(' (')\n",
    "        else:\n",
    "            issues1.append(row)\n",
    "            fixes1.append(row[len(row)-2:len(row)])\n",
    "\n",
    "issues1.append('\\\\n')\n",
    "issues1.append('\\\\t')\n",
    "issues1.append('\\\\')\n",
    "\n",
    "issues2.append('[0-9]')\n",
    "issues2.append('\\s\\'$')\n",
    "issues2.append('^\\'')\n",
    "issues2.append('\\,[a-z]*,*$')\n",
    "issues2.append('\\'\\\"?$')\n",
    "\n",
    "fixes1.append('')\n",
    "fixes1.append('')\n",
    "fixes1.append('')\n",
    "\n",
    "fixes2.append('')\n",
    "fixes2.append('')\n",
    "fixes2.append('')\n",
    "fixes2.append('')\n",
    "fixes2.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm really starting to wonder about alicia silverstone. sure, she is one of the most beautiful creatures on god's green earth (second only to that movie critic at large guy ), but when it comes to choosing what movies she stars in, she always strikes out. the crush was a slow-moving, predictable piece of fluff. hideaway was a horrific novel adaptation alicia had only a minor role in. clueless was an annoying, unfunny waste of time. and people have e-mailed me too ,\" saying clueless is a good movie and that i'm the only one who doesn't like it. one girl said if i'd seen the movie with \"\" an open mind \",\" \"\" i would have enjoyed it. nothing could be further from the truth. i went into the theater expecting to love the movie. the preview looked good and of course i'm crazymadinlove with alicia \", but the movie was a bunch of bad jokes coming from whiny, unlikable characters. almost everyone i saw the movie with felt the same way. when we were walking out of the theater, one guy (and it wasn't me) yelled out ,\" \"\" that was the worst f$&#in' movie i've ever seen \"\" and the rest of us had to laugh in agreement. so last night i walked into the video store and saw alicia's pretty face on the cover of some made-for-video thriller called the babysitter. i knew it would be bad but some inner compulsion i'll probably never understand made me rent it anyway. what i got was  minutes of regret--the worst alicia silverstone movie ever. and you already know from the last paragraph what the competition is like. where to begin in criticizing this movie? the plot is a thin shred that moves slower than a glacier \", the writing could have been done (and for all we know it was) by a ten year old, alicia is the star and she's still wasted in a movie that has no appeal whatsoever. there is zero humor, zero suspense, zero drama and zero action, until the last ten minutes, when the story is needlessly and pointlessly concluded with a violent sequence. zero plus zero plus zero plus zero equals zero. so why does this movie get one star out of me? well, alicia spends twenty minutes of the movie in the bathtub. and if it wasn't bubble bath, the babysitter would have instantly joined the ranks of our other four- star features, but you settle for what you can get. alicia plays a babysitter who's spending friday night looking after two kids whose parents are out getting drunk at a cocktail party. and of course anyone as beautiful as alicia automatically spends their friday nights at home (at least that movie critic at large guy does ). as the movie trods along, we discover she's not only the mostly-silent star of the movie but also the object of every male character's fantasies (and probably every male viewer's too ). the drunken father thinks she's just the thing to recapture his lost youth, her boyfriend lets his imagination run wild while spying on alicia from outside, even the prepubescent boy looks in on alicia through the bathroom keyhole while she's taking her bubble bath. they even throw in the middle aged wife's fantasies about a male counterpart at the party. not that any of us asked or ever even thought about seeing this + pound woman in a black silk teddy. at least none of the sex fanatasies ever leave the realm of the pg-rated. in fact, i could imagine the babysitter becoming a cinemax late-night staple if not for the fact that there's absolutely no nudity in it. so you can't call it a sex flick. i've already pointed out that it can't fall under drama, comedy, thriller or action, so what do you classify the babysitter as? bad. \n"
     ]
    }
   ],
   "source": [
    "cleandata1 = pd.Series(data.iloc[:,0])\n",
    "count = 0\n",
    "while (count < len(issues1)):\n",
    "    #print(issues[count])\n",
    "    cleandata1 = cleandata1.str.replace(issues1[count], fixes1[count], regex=False)\n",
    "    count = count + 1\n",
    "count = 0\n",
    "while (count < len(issues2)):\n",
    "    #print(issues[count])\n",
    "    cleandata1 = cleandata1.str.replace(issues2[count], fixes2[count], regex=True)\n",
    "    count = count + 1\n",
    "print(cleandata1.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Term Document Matrix From a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english', max_features = 100)\n",
    "X = vectorizer.fit_transform(cleandata1)\n",
    "ColumnNames=vectorizer.get_feature_names()\n",
    "#print(ColumnNames)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Label  actually  alicia  babysitter  bad  bath  best  \\\n",
      "Review #1: Positive  Positive         2       0           0    1     0     1   \n",
      "Review #2: Positive  Positive         0       0           0    2     0     0   \n",
      "Review #3: Negative  Negative         0      11           5    3     2     0   \n",
      "Review #4: Negative  Negative         2       0           0    1     0     1   \n",
      "Review #5: Negative  Negative         0       0           0    0     1     1   \n",
      "\n",
      "                     big  bit  buy  ...  time  ve  ve seen  wants  work  \\\n",
      "Review #1: Positive    1    3    3  ...     2   2        2      1     0   \n",
      "Review #2: Positive    0    2    0  ...     0   0        0      0     0   \n",
      "Review #3: Negative    0    0    0  ...     1   2        1      0     0   \n",
      "Review #4: Negative    1    2    0  ...     1   0        0      0     1   \n",
      "Review #5: Negative    2    0    0  ...     0   2        1      2     2   \n",
      "\n",
      "                     world  year  zero  zero plus  zero plus zero  \n",
      "Review #1: Positive      3     0     0          0               0  \n",
      "Review #2: Positive      0     1     0          0               0  \n",
      "Review #3: Negative      0     1     9          3               3  \n",
      "Review #4: Negative      0     1     0          0               0  \n",
      "Review #5: Negative      0     1     0          0               0  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "TDM1=pd.DataFrame(X.toarray(),columns=ColumnNames, index = RowNames)\n",
    "#print(data[\"Label\"])\n",
    "TDM1.insert(0, \"Label\", list(data[\"Label\"]), True) \n",
    "print(TDM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from CSV into a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n,'Mike\\'s Pizza High Point, NY Service was very slow and the quality was low. You would think they would know at least how to make good pizza, not. Stick to pre-made dishes like stuffed pasta or a salad. You should consider dining else where.',,\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('RestaurantSentimentCleanerLABELEDDataSMALLSAMPLE.csv', delimiter='\\n', header = None)\n",
    "data = data.drop(0, axis = 0)\n",
    "data = data.rename(columns={0: 'Comments'})\n",
    "data[\"Label\"] = np.nan\n",
    "#print(data.head(10))\n",
    "print(data.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Comments     Label\n",
      "1  'Mike\\'s Pizza High Point, NY Service was very...  Negative\n",
      "2  'i really like this buffet restaurant in Marsh...  Negative\n",
      "3  'After I went shopping with some of my friend,...  Negative\n",
      "4  'Olive Oil Garden was very disappointing. I ex...  Negative\n",
      "5  'The Seven Heaven restaurant was never known f...  Negative\n",
      "6  I went to XYZ restaurant and loved it. I had a...  Positive\n",
      "7  I went to ABC restaurant two days ago and I re...  Positive\n",
      "8  I went to the Chilis on Erie Blvd and had the ...  Positive\n",
      "9  OMG. This restaurant is great. The receptionis...  Positive\n"
     ]
    }
   ],
   "source": [
    "for row in data.index:\n",
    "    a = data.iloc[row-1,0]\n",
    "    if a[0] == 'p':\n",
    "        data.iloc[row-1,0] = a[2:len(a)]\n",
    "        data.iloc[row-1,1] = 'Positive'\n",
    "    else:\n",
    "        data.iloc[row-1,0] = a[2:len(a)]\n",
    "        data.iloc[row-1,1] = 'Negative'\n",
    "\n",
    "RowNames = \"Review #\" + data.index.map(str) + ': ' + data[\"Label\"]\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning for the Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses regual Expressions to find extra texts to remove for later\n",
    "\n",
    "mylist = data.to_string()\n",
    "ntl = re.findall(r\"\\s.\\s|[0-9]\",mylist)\n",
    "new_ntl = list(dict.fromkeys(ntl))\n",
    "issues1 = []\n",
    "fixes1 = []\n",
    "issues2 = []\n",
    "fixes2 = []\n",
    "\n",
    "#print(new_ntl)\n",
    "for row in new_ntl:\n",
    "    if not any(a.isalnum() for a in row):\n",
    "        if row == ' ( ':\n",
    "            issues1.append(' ( ')\n",
    "            fixes1.append(' (')\n",
    "        else:\n",
    "            issues1.append(row)\n",
    "            fixes1.append(row[len(row)-2:len(row)])\n",
    "\n",
    "issues1.append('\\\\n')\n",
    "issues1.append('\\\\t')\n",
    "issues1.append('\\\\')\n",
    "\n",
    "issues2.append('[0-9]')\n",
    "issues2.append('\\',*$')\n",
    "issues2.append('^\\'')\n",
    "\n",
    "fixes1.append('')\n",
    "fixes1.append('')\n",
    "fixes1.append('')\n",
    "\n",
    "fixes2.append('')\n",
    "fixes2.append('')\n",
    "fixes2.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike's Pizza High Point, NY Service was very slow and the quality was low. You would think they would know at least how to make good pizza, not. Stick to pre-made dishes like stuffed pasta or a salad. You should consider dining else where.\n"
     ]
    }
   ],
   "source": [
    "cleandata2 = pd.Series(data.iloc[:,0])\n",
    "count = 0\n",
    "while (count < len(issues1)):\n",
    "    #print(issues[count])\n",
    "    cleandata2 = cleandata2.str.replace(issues1[count], fixes1[count], regex=False)\n",
    "    count = count + 1\n",
    "count = 0\n",
    "while (count < len(issues2)):\n",
    "    #print(issues[count])\n",
    "    cleandata2 = cleandata2.str.replace(issues2[count], fixes2[count], regex=True)\n",
    "    count = count + 1\n",
    "print(cleandata2.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Term Document Matrix From a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english', max_features = 100)\n",
    "X = vectorizer.fit_transform(cleandata2)\n",
    "ColumnNames=vectorizer.get_feature_names()\n",
    "#print(ColumnNames)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Label  abc  appetizer  asked  bring  came  cold  \\\n",
      "Review #1: Negative  Negative    0          0      0      0     0     0   \n",
      "Review #2: Negative  Negative    0          0      0      0     0     0   \n",
      "Review #3: Negative  Negative    0          0      0      0     0     0   \n",
      "Review #4: Negative  Negative    0          0      0      0     0     1   \n",
      "Review #5: Negative  Negative    0          0      1      2     0     0   \n",
      "Review #6: Positive  Positive    0          1      1      0     0     0   \n",
      "Review #7: Positive  Positive    1          0      0      0     1     0   \n",
      "\n",
      "                     coupon  definitely  delicious  ...  salad  seated  \\\n",
      "Review #1: Negative       0           0          0  ...      1       0   \n",
      "Review #2: Negative       0           1          0  ...      0       0   \n",
      "Review #3: Negative       0           0          0  ...      0       0   \n",
      "Review #4: Negative       0           0          0  ...      0       0   \n",
      "Review #5: Negative       0           0          0  ...      0       0   \n",
      "Review #6: Positive       2           0          0  ...      1       0   \n",
      "Review #7: Positive       0           1          1  ...      0       1   \n",
      "\n",
      "                     service  took  took minutes  took minutes bring  waited  \\\n",
      "Review #1: Negative        1     0             0                   0       0   \n",
      "Review #2: Negative        0     0             0                   0       0   \n",
      "Review #3: Negative        0     0             0                   0       0   \n",
      "Review #4: Negative        1     0             0                   0       0   \n",
      "Review #5: Negative        1     1             1                   1       0   \n",
      "Review #6: Positive        0     0             0                   0       0   \n",
      "Review #7: Positive        1     0             0                   0       0   \n",
      "\n",
      "                     waited minutes  waiter  went  \n",
      "Review #1: Negative               0       0     0  \n",
      "Review #2: Negative               0       0     0  \n",
      "Review #3: Negative               0       0     2  \n",
      "Review #4: Negative               0       0     0  \n",
      "Review #5: Negative               0       1     0  \n",
      "Review #6: Positive               0       0     1  \n",
      "Review #7: Positive               0       0     1  \n",
      "\n",
      "[7 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "TDM2=pd.DataFrame(X.toarray(),columns=ColumnNames, index = RowNames)\n",
    "#print(data[\"Label\"])\n",
    "TDM2.insert(0, \"Label\", list(data[\"Label\"]), True) \n",
    "print(TDM2.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Term Document Matrix From a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['Comments'])\n",
    "ColumnNames=vectorizer.get_feature_names()\n",
    "#print(ColumnNames)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM=pd.DataFrame(X.toarray(),columns=ColumnNames, index = RowNames)\n",
    "print(TDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo, but with Additional Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', analyzer=stemmed_words, min_df = 2)\n",
    "X = vectorizer.fit_transform(data['Comments'])\n",
    "ColumnNames=vectorizer.get_feature_names()\n",
    "#print(ColumnNames)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM=pd.DataFrame(X.toarray(),columns=ColumnNames, index = RowNames)\n",
    "print(TDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo, but with Additional Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', analyzer=stemmed_words, min_df = 2)\n",
    "X = vectorizer.fit_transform(data['Comments'])\n",
    "ColumnNames=vectorizer.get_feature_names()\n",
    "#print(ColumnNames)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM=pd.DataFrame(X.toarray(),columns=ColumnNames, index = RowNames)\n",
    "print(TDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Term Document Matrix From a Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(input='filename')\n",
    "X = vectorizer.fit_transform(FilePaths)\n",
    "ColumnNames=vectorizer.get_feature_names()\n",
    "#print(ColumnNames)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM=pd.DataFrame(X.toarray(),columns=ColumnNames, index = FileNames)\n",
    "print(TDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Corpus from a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converts each row in the DataFrame's Column 'Comments' into its own individual file to create a corpus\n",
    "\n",
    "i = 1\n",
    "for row in data.index:\n",
    "    if data.iloc[row-1,1] == 'Positive':\n",
    "        file_title = '/Users/gml/Desktop/test2/PositiveReview{}.txt'.format(i)\n",
    "        np.asarray(data.values[row-1][0],dtype=np.object).tofile(file_title, sep=\",\", format=\"%s\")\n",
    "    else:\n",
    "        file_title = '/Users/gml/Desktop/test2/NegativeReview{}.txt'.format(i)\n",
    "        np.asarray(data.values[row-1][0],dtype=np.object).tofile(file_title, sep=\",\", format=\"%s\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 ='/Users/gml/Desktop/test2'\n",
    "FullFileName=os.listdir(path3)\n",
    "print(FullFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect File Names from Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 ='/Users/gml/Desktop/test1'\n",
    "FullFileName=os.listdir(path2)\n",
    "print(FullFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilePaths=[]\n",
    "FileNames=[]\n",
    "\n",
    "for name in os.listdir(path2):\n",
    "    if name != '.DS_Store': #Mac Medata file\n",
    "        #print(path2+ \"\\\\\" + name)\n",
    "        next=path2+ \"/\" + name\n",
    "    \n",
    "        nextnameL=name.split(\".\")   ##.txt out of name\n",
    "        nextname=nextnameL[0]   ## provides file name\n",
    "    \n",
    "        FilePaths.append(next)\n",
    "        FileNames.append(nextname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
